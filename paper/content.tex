%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Here's a text citation of \citet{OliveiraJr2015}
and a another version that is sometimes used \citep{OliveiraJr2015}.

The different gridding methods, such as inverse-distance weights, polynomical fitting, spline functions (Briggs, 1974), often assume potential data are not harmonic functions. However, the total field anomaly is harmonic when the magnitude is much smaller than the magnitude of the geomagnetic field; this is true for most instances in which the total field anomaly is observed. 

Airborne data often have more data points along flight lines and much larger gaps between flight lines. The equivalent source (EQS) technique takes into account the irregularly spaced grids and the variable heights of the observed data. The EQS technique can be used for reduction to the pole, upwards continuation, modelling the lithospheric magnetic field, etc.

The norm of the magnetic field is less dependent on the direction of magnetisation. This is particularly useful for areas with remanent magnetisation, low magnetic latitudes, sources with shallow inclination directions and sources with an unknown magnetised directions (Hidalgo-Gato, et al., 2021; Melo, et al., 2021). By calculating the norm of the magnetic anomalous field, the data is less dependent on the direction of Earth’s main field and crustal magnetisation.

\lipsum[1-3]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Methodology}

The observed total field anomaly ($\Delta T$) is the difference between the measured norm of the total magnetic field ($\vec{\mathbf{T}}$) and the norm of the regional reference field ($\vec{\mathbf{F}}$, usually represented by the IGRF) at the time of measurement:

\begin{equation}
    \Delta T = \left\lVert \vec{\mathbf{T}} \right\rVert - \left\lVert \vec{\mathbf{F}} \right\rVert
    \ .
\end{equation}

\noindent
The total magnetic field ($\vec{T}$) is the sum of the anomalous magnetic field vector ($\vec{\mathbf{B}}$) and the regional field vector ($\vec{\mathbf{F}}$) (cite Blakley, 1996, Langel and Hinze, 1998, \citep{OliveiraJr2015}). The total field anomaly ($\Delta T$) can therefore be given by

\begin{equation}
    \Delta T = \left\lVert \vec{\mathbf{F}} + \vec{\mathbf{B}} \right\rVert - \left\lVert \vec{\mathbf{F}} \right\rVert
    \ .
\end{equation}

For the majority of crustal anomalies measured by airborne and shipborne surveys, $\vec{\mathbf{B}}$ is much smaller in magnitude compared to $\vec{\mathbf{F}}$. Additionally, $\vec{\mathbf{F}}$ can be considered constant on these local to regional scales. Subsequently, $\Delta T$ can be approximated as

\begin{equation}
\label{'eq:tfa dot product'}
    \Delta T\approx  \vec{\mathbf{B}} \cdot \hat{\mathbf{F}}
    \ ,
\end{equation}

\noindent
in which $\hat{\mathbf{F}}$ is a unit vector in the same direction as the regional field. Thus, $\Delta T$ is approximately a harmonic function (cite Blakely, 1996; \citep{OliveiraJr2015}).

\subsection{Equivalent Source Technique}

The equivalent source technique assumes any harmonic function \textcolor{orange}{$d(x, y, z)$} can be approximated by the sum of $M$ discrete point source effects,

\begin{equation}
\label{'eq:eqs technique'}
\textcolor{orange}{d (x, y, z)} = \sum_{j=1}^{M} a(x, y, z, x'_j, y'_j , z'_j) \textcolor{teal}{c_j}
\ ,
\end{equation}

\noindent
where \textcolor{orange}{$d (x, y, z)$} is the predicted data with Cartesian positions $x$ and $y$ pointing in the geographic north and east directions, respectively, and $z$ pointing upwards. For $M$ point sources, $a(x, y, z, x'_j, y'_j , z'_j)$ are the source effects (for $j = 1, ..., M$), where $(x', y', z')$ are the Cartesian positions of the sources to the observation points in the same coordinate system as the data, \textcolor{teal}{$c_j$} are the associated source coefficients (cite dampney 1969, \cite{Cordell1992}).

For magnetic surveys, \textcolor{orange}{$d (x, y, z)$} from Equation~\ref{'eq:eqs technique'} becomes \textcolor{orange}{$\Delta T(x, y, z)$} for N number of data points with Cartesian positions $(x, y, z)$ where $x$ and $y$ point in the geographic north and east directions, respectively, and $z$ points upwards. The point source effects, $a(x, y, z, x'_j, y'_j , z'_j)$, are therefore $\vec{\mathbf{B}} \cdot \hat{\mathbf{F}}$ from Equation~\ref{'eq:tfa dot product'}, where $\vec{\mathbf{B}}$ is the magnetic field of dipole given by:
\begin{equation}
    \vec{\mathbf{B}} = C_m \frac{m}{r^3} [3 ( \hat{\mathbf{m}} \cdot \hat{\mathbf{r}}) \hat{\mathbf{r}} - \hat{\mathbf{m}}]
    \ .
\end{equation}
\noindent
Here $C_m = \frac{\mu_0}{4 \pi} = 10^{-7} \ \text{Hm}^{-1}$ is the proportionality constant where $\mu_0$ is the magnetic permeability of free space, $\hat{\mathbf{m}}$ is the dipole moment unit vector and
\begin{equation}
    r = \sqrt{(x - x')^2 + (y - y')^2 + (z - z')^2}
    \ ,
\end{equation}
the vector from the dipole source to the observation point (cite Blakely 1996). If the moment magnitude, $m$, is equal to 1, the coefficients, \textcolor{teal}{$c_j$}, from Equation~\ref{'eq:eqs technique'} becomes the norm of the moment magnitude:
\begin{equation}
\label{'eq:tfa_eqs'}
\textcolor{orange}{\Delta T (x, y, z)} = \sum_{j=1}^{M}  \vec{\mathbf{B}}(x, y, z, x'_j, y'_j, z'_j) \cdot \hat{\mathbf{F}} \textcolor{teal}{\left\lVert \vec{\mathbf{m}_j} \right\rVert}
\ .
\end{equation}

This can also be expressed in matrix form:
\begin{equation}
\textcolor{orange}{\begin{bmatrix}
    \Delta T_1 \\ \Delta T_2 \\ \vdots \\ \Delta T_N
\end{bmatrix}_{Nx1}} = \begin{bmatrix}
    \mathbf{B}_{11} \cdot \hat{\mathbf{F}} & \mathbf{B}_{12} \cdot \hat{\mathbf{F}} & \hdots & \mathbf{B}_{1M} \cdot \hat{\mathbf{F}} \\
    \mathbf{B}_{21} \cdot \hat{\mathbf{F}} & \mathbf{B}_{22} \cdot \hat{\mathbf{F}} & \hdots & \mathbf{B}_{2M} \cdot \hat{\mathbf{F}} \\
    \vdots & \vdots & \vdots & \vdots \\
    \mathbf{B}_{N1} \cdot \hat{\mathbf{F}} & \mathbf{B}_{N2} \cdot \hat{\mathbf{F}} & \hdots & \mathbf{B}_{NM} \cdot \hat{\mathbf{F}} \\
\end{bmatrix}_{NxM} \textcolor{teal}{\begin{bmatrix}
    \left\lVert \vec{\mathbf{m}_1} \right\rVert \\ \left\lVert \vec{\mathbf{m}_2} \right\rVert \\ \vdots \\ \left\lVert \vec{\mathbf{m}_M} \right\rVert
\end{bmatrix}_{Mx1}}
\end{equation}
which is also in the linear system,
\begin{equation}
    \textcolor{orange}{\bar{\mathbf{d}}} = \bar{\bar{A}} \textcolor{teal}{\bar{\mathbf{c}}}
    \ ,
\end{equation}
where $\mathbf{d}$ is the column vector of $N$ predicted values at the observation points, $\mathbf{c}$ is the column vector of $M$ coefficients (norm of the moment magnitudes) and $A$ is the $N \times M$ sensitivity (Jacobian) matrix. Using the damp least squares solution, the goal function, $\phi$, is:
\begin{equation}
\label{'eq:goal function'}
    \phi = \bar{\mathbf{r}}^T\bar{\mathbf{r}} + \mu \textcolor{teal}{\bar{\mathbf{c}}^T\bar{\mathbf{c}}}
    \ ,
\end{equation}
where $\mu \textcolor{teal}{\bar{\mathbf{c}}^T\bar{\mathbf{c}}}$ is the regularisation function and  $\bar{\mathbf{r}}^T\bar{\mathbf{r}}$ is the data misfit function where $\bar{r}$ is the residual between the observed and predicted data:
\begin{equation}
    \bar{\mathbf{r}} = \bar{\mathbf{d^0}} - \textcolor{orange}{\bar{\mathbf{d}}}
    \ .
\end{equation}
Consequently, the goal function from Equation~\ref{'eq:goal function'} can  be expanded to give:
\begin{equation}
    \phi (\textcolor{teal}{\bar{\mathbf{c}}}) = (\bar{\mathbf{d}^0} - \Bar{\Bar{A}} \textcolor{teal}{\bar{\mathbf{c}}})^T (\bar{\mathbf{d}^0} - \Bar{\Bar{A}} \textcolor{teal}{\bar{\mathbf{c}}}) + \mu \textcolor{teal}{\bar{\mathbf{c}}^T\bar{\mathbf{c}}}
    \ .
\end{equation}
By minimising the goal function, the values of the source coefficients $\textcolor{teal}{\bar{\mathbf{c}}}$ that best fit the observed field values can be obtained. If the residual is as close as possible to zero, the observed and predicted data are very similar. Therefore, the smallest $\phi(\textcolor{teal}{\bar{c}})$
gives the best fit, which can be calculated by taking the gradient of $\phi(\textcolor{teal}{\bar{c}})$ and equating it to the null vector
\begin{equation}
    \nabla_{\textcolor{teal}{\bar{c}}} \phi = 2 \Bar{\Bar{A}}^T \Bar{\Bar{A}} \textcolor{teal}{\Bar{\mathbf{c}}} - 2\Bar{\Bar{A}}^T\bar{\mathbf{d}^0} + 2\mu \textcolor{teal}{\bar{\mathbf{c}}} = \bar{\mathbf{0}}
    \ .
\end{equation}
This can be rearranged to express the normal equation system:
\begin{equation}
    (\Bar{\Bar{A}}^T \Bar{\Bar{A}} + \Bar{\Bar{I}} \mu ) \textcolor{teal}{\bar{\mathbf{c}}} = 
    \Bar{\Bar{A}}^T\bar{\mathbf{d}^0}
    \ ,
\end{equation}
which can be solved for \textcolor{teal}{$\bar{c}$}. Once \textcolor{teal}{$\bar{c}$} has been fitted to the data, Equation~\ref{'eq:eqs technique'} can be used to forward model for any field in any ($x, y, z$) location.


\subsection{Norm of B Predictions}
The anomalous magnetic field vector ($\vec{\mathbf{B}}$) at the $ith$ data point for $i = 1,...,N$ is given by:
\begin{equation}
    \mathbf{B}_i(x,y,z) = \sqrt{B^2_{x_i} + B^2_{y_i} +B^2_{z_i}}
\end{equation}
where where $B_{x_i}$, $B_{y_i}$ and $B_{z_i}$ are the three components of the anomalous magnetic field vector in the geographic easting, geographic northing and upwards direction, respectively. We can therefore adapt Equation~\ref{'eq:tfa_eqs'} to predict the norm of the anomalous magnetic field:
\begin{equation}
\textcolor{orange}{\left\lVert \vec{\mathbf{B}}_{i}(x,y,z) \right\rVert} = \sum_{j=1}^{M}  \left\lVert \vec{\mathbf{B}}_{j}(x,y,z) \right\rVert \textcolor{teal}{\left\lVert \vec{\mathbf{m}_j} \right\rVert}
\ .
\end{equation}


\subsection{Dual Layer Concept}
Two layers of equivalent sources was used to fit both, the regional magnetic field and the shallow magnetic anomalies. \citep{Li2019} found having an additional deeper layer of equivalent sources reduced the misfit, especially for the long‐wavelength fields. By using two layers, the deeper equivalent source layer can capture the regional, long-wavelength signals, whilst the shallower layer can capture the short-wavelength signals.

For this dual layer process, firstly the deep layer of equivalent sources is calculated to determine the regional magnetic field. The deep layer has much fewer equivalent soruces compared to the number of data points in order to only capture the longer-wavelength signals. To determine the depth of this layer, a lower and upper bound of 2.5 and 6 times the average 0distance of the nearest neighbouring data point was used \citep{Dampney1969}. The residual field between the observed data and the deep equivalent source layer prediction is calculated. This residual field is then fitted by the shallow layer of equivalent sources. The shallow layer has the same amount of equivalent sources as the number of data points. After fitting the shallow equivalent layer, the final prediction can be determined by adding both, the deep and shallow, equivalent source layer predictions.

Block averaging the data reduces the computational load and the likelihood of over-fitting the data. Due to the nature of aliasing flight line data, block averaging can balance the equivalent sources along and on adjacent flight lines to reduce this effect \citep{SolerUieda2021}. Furthermore, by block averaging the data when calculating the deep equivalent sources, only the long-wavelength signals are captured, rather than both short and long wavelength signals. When the block average is too small, more short wavelength signals are captured and not all of the long wavelength signals from the regional field are captured. Too large block averaging, not all the regional signals are captured either. Therefore, different block averaging sizes were calculated to determine the optimum size for capturing only the long wavelength signals. To further reduce the computational load when calculating the shallow equivalent sources, block averaging the same size as the grid spacing of the predicted data was applied.

\subsection{Gradient Boosting}
Estimating the source coefficients (\textcolor{teal}{$\bar{c}$}) using the damp least-squares solution is very computationally demanding, especially on a regional scale due to the large number of data points. To overcome this problem, \citet{SolerUieda2021} adapted the gradient boosting method from \citet{Friedman2001} in which the least-squares solution can be determined by fitting additive models to the pseudo-residuals which are updated at each step. Using this method, (\textcolor{teal}{$\bar{c}$}) is estimated in overlapping windows and carried out iteratively. To improve the accuracy of the prediction, \citet{SolerUieda2021} also selected the windows randomly following \citet{Friedman2002}. This gradient boosting method reduces the computational load by solving for numerous smaller damp least-squares solutions rather than one large solution:
\begin{enumerate}
    \item Define $M$ number of equivalent sources with the same easting and northing coordinates as the data.
    \item Determine a set of overlapping windows that are equal in size and cover the whole survey area.
    \item Randomly select a window.
    \item Fit the data in the selected window using the equivalent sources.
    \item Using the equivalent sources, predict on all of the data.
    \item Calculate the (pseudo-)residual.
    \item Randomly select another window.
    \item Fit the residuals in the newly selected window using the equivalent sources in that window.
    \item Predict on all of the data and update the (pseudo-)residual.
    \item Repeat steps 7 to 9 until all the windows have been used.
\end{enumerate}
This method was applied to the shallow layer of equivalent sources (see the Dual Layer Concept chapter).

\subsection{Block K-Fold Cross-Validation}
The model requires manual parameter selection for the damping, depth of equivalent sources and window size for the gradient boosting. In order to select the optimal parameter combination, K-Fold Crosss Validation (K-CV) was used. K-CV is a popular machine learning method often used for model selection. Data is divided into k number of folds, that are as equal as possible in size. One of the k folds is used as testing set and the remaining (k-1) folds are used as training sets. This is repeated iteratively until all k folds have been used as both testing and training sets:
\begin{enumerate}
    \item Split the data into blocks that are equal as possible in size.
    \item Split the blocks into K number of folds.
    \item Assign the first fold, $Fold_i$ (for $i= 1,..., K$), to the testing set and the remaining folds to the training set.
    \item Fit the equivalent sources using the training dataset and the first parameter set.
    \item Predict on the testing dataset and calculate the RMSE.
    \item Then assign the next fold ($Fold_{i+1}$) to the testing dataset and the remaining folds to the training dataset.
    \item Repeat steps 4 and 5.
    \item Continue repeating steps 4 and 5 until all folds have been used as both testing and training datasets.
    \item Calculate the CV-RMSE for the parameter set by taking the average of all the RMSEs from each fold.
    \item Repeat all steps for each parameter set.
\end{enumerate}
The K-CV error estimation is the root mean square error (RMSE) of all the errors from each fold calculation. The parameter combination with the smallest RMSE is selected for the model.
 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Synthetic Data Application}

\subsection{With and without dual layer}
* w/o dual layer - doesn't capture all of the regional signal

\subsection{Block average deep sources versus regular grids (for shallow we cite Santi):}
Block average the data to make it smaller and smoother. Show that this works.
Block average source positions instead of regular grid to avoid issues with no-data regions.

\subsection{Single synthetic model}
Use the coordinates from a survey (ICEGRAV) and make a dipole model that is relatively complex but doesn't have to be exactly like the data. Must have regional and shallow sources.


\subsection{Part 1}
Description of the model and data locations.

\subsection{Part 2}
Show the results for our method. Use the block averaging for deep sources + GB for shallow and predict a grid of TFA and |B|. Show maps of the block reduced sources and data, residuals after only deep sources, residuals of the TFA after gradient boosting, grid predictions (deep + shallow) of TFA and |B|.

\subsection{Part 3}
Difference between using the dual-layer or the single shallow layer. Maps showing the differences in TFA and |B|.

\subsection{Part 4}
Block averaging vs regular grid for deep sources. Effects on no-data zones when we use regular grid versus block averaged sources (maps showing the error). Difference in computation time between (1) Block averaged data and sources (2) Blocked averaged sources but original data (3) grid sources and original data (bar plot showing the difference in computation time).

\subsection{Brief discussion (or in a separate section)}

%\begin{figure}[tb]
%\centering
%\includegraphics[width=1\linewidth]{figures/simple-synthetic-data.png}
%\caption{
  %\lipsum[1]
%}
%\label{fig_synthetic_simple_data}
%\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Real Data Application}

\subsection{Apply the standard method to ICEGRAV}

\subsection{Describe ICEGRAV}

\subsection{Show the original data (TFA points)}

\subsection{Show the location of the deep sources and the block averaged data}

\subsection{Show residuals from deep sources}

\subsection{Show residuals from GB}

\subsection{Grid predictions of TFA and |B|}

\subsection{Brief discussion (or in a separate section)}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\lipsum[1]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Open research}

The Python source code used to produce all results and figures presented here
is available at \url{https://github.com/\GitHubRepository} and
\url{https://doi.org/\ArchiveDOI} under the MIT open-source license.

Here we should cite all of the main software used, like Jupyter, numpy, scipy,
matplotlib, Fatiando, etc.

Cite any data sources as well.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

We are indebted to the developers and maintainers of the open-source software
without which this work would not have been possible.
Acknowledge any non-author contributors to this study.
Statement about funding.

% Thank the editors and reviewers after review.
