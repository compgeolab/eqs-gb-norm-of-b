%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Here's a text citation of \citet{OliveiraJr2015}
and a another version that is sometimes used \citep{OliveiraJr2015}.

The different gridding methods, such as inverse-distance weights, polynomical fitting, spline functions (Briggs, 1974), often assume potential data are not harmonic functions. However, the total field anomaly is harmonic when the magnitude is much smaller than the magnitude of the geomagnetic field; this is true for most instances in which the total field anomaly is observed. 

Airborne data often have more data points along flight lines and much larger gaps between flight lines. The equivalent source (EQS) technique takes into account the irregularly spaced grids and the variable heights of the observed data. The EQS technique can be used for reduction to the pole, upwards continuation, modelling the lithospheric magnetic field, etc.

The norm of the magnetic field is less dependent on the direction of magnetisation. This is particularly useful for areas with remanent magnetisation, low magnetic latitudes, sources with shallow inclination directions and sources with an unknown magnetised directions (Hidalgo-Gato, et al., 2021; Melo, et al., 2021).

\lipsum[1-3]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Methodology}
The observed total field anomaly vector ($\Delta T$) is the difference between the magnetic total field intensity vector ($\vec{T}$) measured and the regional reference field vector ($\vec{F}$) at the time of measurement:
\begin{equation}
    \Delta T = \left\lVert \vec{T} \right\rVert - \left\lVert \vec{F} \right\rVert
    \ .
\end{equation}
$\vec{T}$ is the sum of the anomalous magnetic field vector ($\vec{B}$) and $\vec{F}$ (cite Blakley, 1996, Langel and Hinze, 1998, \citep{OliveiraJr2015}). $\Delta T$ can therefore be given by:
\begin{equation}
    \Delta T = \left\lVert \vec{F} + \vec{B} \right\rVert - \left\lVert \vec{F} \right\rVert
    \ .
\end{equation}
For the majority of crustal anomalies measured by airborne and shipborne surveys, $\vec{B}$ is much smaller in magnitude compared to $\vec{F}$. Additionally, $\vec{F}$ can be considered constant on these local to regional scales. Subsequently, $\Delta T$ can be approximated as the dot product of $\vec{B}$ and the regional field direction ($\hat{F}$),
\begin{equation}
\label{'eq:tfa dot product'}
    \Delta T\approx  \vec{B} \cdot \hat{F}
    \ ,
\end{equation}
thus enabling $\Delta T$ to be harmonic (cite Blakely, 1996; \citep{OliveiraJr2015}).

\subsection{Equivalent Source Technique}
The equivalent source technique assumes any harmonic function \textcolor{orange}{$d_i$} can be approximated by the sum of $M$ discrete point source effects,
\begin{equation}
\label{'eq:eqs technique'}
\textcolor{orange}{d_i} = \sum_{j=1}^{M}  f_{ij} \textcolor{teal}{c_j}
\ ,
\end{equation}
where \textcolor{orange}{$d_i$} is the predicted data at $N$ observation points with $i = 1, ... , N$, $f_{ij}$ is the $M$ point source effects with $j = 1, ..., M$ and \textcolor{teal}{$c_j$} is the associated coefficients for the $M$ point source effects (cite dampney 1969, \cite{Cordell1992}).

For magnetic surveys, {$d_i$} from Equation~\ref{'eqs technique'} becomes \textcolor{orange}{$\Delta T(x, y, z)$} for N number of data points with Cartesian positions $(x_i, y_i, z_i)$, where $x_i$ and $y_i$ point in the geographic north and east directions, respectively, and $z_i$ points upwards. $f_{ij}$ is therefore $\vec{B} \cdot \hat{F}$ from Equation~\ref{'eq:tfa dot product'}, where $\vec{B}$ is the magnetic field of dipole given by:
\begin{equation}
    \vec{B} = \frac{C_m}{r^3} [3 ( \hat{m} \cdot \hat{r}) \hat{r} - \hat{m}]
    \ ,
\end{equation}
in which $C_m = \frac{\mu_0}{4 \pi} = 10^{-7} Henry \cdot meter^{-1}$ is the proportionality constant where $\mu_0$ is the magnetic permeability of free space, $ \vec{m} = m \hat{m}$ is the dipole moment, and $\vec{r} = r \hat{r} $ is the vector from the dipole source to the observation point (cite Blakely 1996). If the moment magnitude, $m$, is equal to 1, the coefficients, \textcolor{teal}{$c_j$}, from Equation~\ref{'eq:eqs technique'} becomes the norm of the moment magnitude:
\begin{equation}
\textcolor{orange}{\Delta T (x, y, z)} = \sum_{j=1}^{M}  \vec{B_j}(x, y, z) \cdot \hat{F_i} \textcolor{teal}{\left\lVert \vec{m_j} \right\rVert}
\ .
\end{equation}
This can also be expressed in matrix form:
\begin{equation}
\textcolor{orange}{\begin{bmatrix}
    \Delta T_1 \\ \Delta T_2 \\ \vdots \\ \Delta T_N
\end{bmatrix}_{Nx1}} = \begin{bmatrix}
    B_{11} \cdot F_{1} & B_{12} \cdot F_{1} & \hdots & B_{1M} \cdot F_{1} \\
    B_{21} \cdot F_{2} & B_{22} \cdot F_{2} & \hdots & B_{2M} \cdot F_{2} \\
    \vdots & \vdots & \vdots & \vdots \\
    B_{N1} \cdot F_{N} & B_{N2} \cdot F_{N} & \hdots & B_{NM} \cdot F_{N} \\
\end{bmatrix}_{NxM} \textcolor{teal}{\begin{bmatrix}
    \left\lVert \vec{m_1} \right\rVert \\ \left\lVert \vec{m_2} \right\rVert \\ \vdots \\ \left\lVert \vec{m_M} \right\rVert
\end{bmatrix}_{Mx1}}
\end{equation}
which is also in the linear system,
\begin{equation}
    \textcolor{orange}{\bar{d}} = \bar{\bar{A}} \textcolor{teal}{\bar{c}}
    \ ,
\end{equation}
where $\mathbf{d}$ is the column vector of $N$ predicted values at the observation points, $\mathbf{c}$ is the column vector of $M$ coefficients (norm of the moment magnitudes) and $\mathbf{A}$ is the $N \times M$ sensitivity (Jacobian) matrix. Using the damp least squares solution, the goal function, $\phi$, is:
\begin{equation}
\label{'eq:goal function'}
    \phi = \bar{r}^T\bar{r} + \mu \textcolor{teal}{\bar{c}^T\bar{c}}
    \ ,
\end{equation}
where $\mu \textcolor{teal}{\bar{c}^T\bar{c}}$ is the regularisation function and  $\bar{r}^T\bar{r}$ is the data misfit function where $\bar{r}$ is the residual between the observed and predicted data:
\begin{equation}
    \bar{r} = \bar{d^0} - \textcolor{orange}{\bar{d}}
    \ .
\end{equation}
Consequently, the goal function from Equation~\ref{'eq:goal function'} can  be expanded to give:
\begin{equation}
    \phi (\textcolor{teal}{\bar{c}}) = (\bar{d^0} - \Bar{\Bar{A}} \textcolor{teal}{\Bar{c}})^T (\bar{d^0} - \Bar{\Bar{A}} \textcolor{teal}{\Bar{c}}) + \mu \textcolor{teal}{\bar{c}^T\bar{c}}
    \ .
\end{equation}
By minimising the goal function, the values of the source coefficients, $c$, that best fit the observed field values can be obtained using the residual. If the residual is as close as possible to zero, the observed and predicted data are very similar. Therefore, the smallest
\begin{equation}
    \phi(\textcolor{teal}{\bar{c}}) = min
\end{equation}
gives the best fit which can be calculated by taking the derivative of $\phi(\textcolor{teal}{\bar{c}})$ and equalling to zero:
\begin{equation}
    \nabla_{\textcolor{teal}{\bar{c}}} \phi = 2 \Bar{\Bar{A}}^T \Bar{\Bar{A}} \textcolor{teal}{\Bar{c}} - 2\Bar{\Bar{A}}^T\bar{d^0} + 2\mu \textcolor{teal}{\bar{c}} = \bar{0}
    \ .
\end{equation}
This can be rearranged to express the normal equation system:
\begin{equation}
    (\Bar{\Bar{A}}^T \Bar{\Bar{A}} + \Bar{\Bar{I}} \mu ) \textcolor{teal}{\bar{c}} = 
    \Bar{\Bar{A}}^T\bar{d^0}
    \ ,
\end{equation}
which can be solved for \textcolor{teal}{$\bar{c}$}, and then forward modelled for any field in any $x, y, z$ location.

    
\subsection{Gradient Boosting}
Estimating the source coefficients (\textcolor{teal}{$\bar{c}$}) that best fit the observed data is computationally demanding. To overcome this problem, \cite{SolerUieda2021} used the gradient boosted method in which (\textcolor{teal}{$\bar{c}$}) is estimated in overlapping windows and carried out iteratively. This gradient boosted method was applied to the shallow layer of equivalent sources (later discussed in the Dual Layer Concept chapter).

\subsection{Norm of B Predictions}
The amplitude of $B$ is weakly dependent on the direction of magnetisation compared the total field anomaly $F$ \citep{HidalgoGato2021}. By calculating the norm of the magnetic anomalous field, the data is less dependent on the direction of Earth’s main field and crustal magnetisation.

\subsection{Dual Layer Concept}
Two layers of equivalent sources was used to fit both, the regional magnetic field and the shallow magnetic anomalies. \citep{Li2019} found having an additional deeper layer of equivalent sources reduced the misfit, especially for the long‐wavelength fields. By using two layers, the deeper equivalent source layer can capture the regional, long-wavelength signals, whilst the shallower layer can capture the short-wavelength signals. For this dual layer process, firstly the deeper layer of equivalent sources is calculated to determine the regional field. To determine the depth of this layer, a lower and upper bound of 2.5 and 6 times the distance of the nearest neighbouring data point respectively was used \citep{Dampney1969}. The residual field between the deep equivalent source layer prediction and the data is then used to calculate the shallow equivalent source layer. Adding both the deep and shallow equivalent source layer predictions together creates the final prediction for the data.

\subsection{Block Averaging}
Block averaging the data reduces the computational load and the likelihood of overfitting the data. Due to the nature of aliasing flight line data, block averaging can balance the equivalent sources along and adjacent flight lines to reduce this effect \citep{SolerUieda2021}. Furthermore, by block averaging the data when calculating the deep equivalent sources, only the long-wavelength signals are captured, rather than both short and long wavelength signals. When the block average is too small, more short wavelength signals are captured and not all of the long wavelength signals from the regional field are captured. Too large block averaging, not all the regional signals are captured either. Therefore, different block averaging sizes were calculated to determine the optimum size for capturing only the long wavelength signals. To reduce the computational load when calculating the shallow equivalent sources, block averaging the same size as the grid spacing of the predicted data was applied.

\subsection{Block K-Fold Cross-Validation}
The model requires manual parameter selection for the damping, depth of equivalent sources and window size for the gradient boosting. In order to select the optimal parameter combination, K-Fold Crosss Validation (K-CV) was used. K-CV is a popular machine learning method often used for model selection. Data is divided into k number of folds, that are as equal as possible in size. One of the k folds is used as testing set and the remaining (k-1) folds are used as training sets. This is repeated iteratively until all k folds have been used as both testing and training sets. The K-CV error estimation is the root mean square error (RMSE) of all the errors from each fold calculation. The parameter combination with the smallest RMSE is selected for the model.

\begin{enumerate}
    \item Split the data into blocks that are equal as possible in size.
    \item Split the blocks into K number of folds.
    \item Assign the first fold, $Fold_i$ (for $i= 1,..., K$), to the testing set and the remaining folds to the training set.
    \item Fit the equivalent sources using the training dataset and the first parameter set.
    \item Predict on the testing dataset and calculate the RMSE.
    \item Then assign the next fold ($Fold_{i+1}$) to the testing dataset and the remaining folds to the training dataset.
    \item Repeat steps 4 and 5.
    \item Continue repeating steps 4 and 5 until all folds have been used as both testing and training datasets.
    \item Calculate the CV-RMSE for the parameter set by taking the average of all the RMSEs from each fold.
    \item Repeat all steps for each parameter set.
\end{enumerate}
 


% KCV on slice data, plot pic of training and testing fold 

% https://ieeexplore.ieee.org/abstract/document/5342427
% https://academic.oup.com/biomet/article-abstract/76/3/503/298209?redirectedFrom=fulltext&login=true


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Synthetic Data Application}

\subsection{With and without dual layer}
* w/o dual layer - doesn't capture all of the regional signal

\subsection{Block average deep sources versus regular grids (for shallow we cite Santi):}
Block average the data to make it smaller and smoother. Show that this works.
Block average source positions instead of regular grid to avoid issues with no-data regions.

\subsection{Single synthetic model}
Use the coordinates from a survey (ICEGRAV) and make a dipole model that is relatively complex but doesn't have to be exactly like the data. Must have regional and shallow sources.


\subsection{Part 1}
Description of the model and data locations.

\subsection{Part 2}
Show the results for our method. Use the block averaging for deep sources + GB for shallow and predict a grid of TFA and |B|. Show maps of the block reduced sources and data, residuals after only deep sources, residuals of the TFA after gradient boosting, grid predictions (deep + shallow) of TFA and |B|.

\subsection{Part 3}
Difference between using the dual-layer or the single shallow layer. Maps showing the differences in TFA and |B|.

\subsection{Part 4}
Block averaging vs regular grid for deep sources. Effects on no-data zones when we use regular grid versus block averaged sources (maps showing the error). Difference in computation time between (1) Block averaged data and sources (2) Blocked averaged sources but original data (3) grid sources and original data (bar plot showing the difference in computation time).

\subsection{Brief discussion (or in a separate section)}

%\begin{figure}[tb]
%\centering
%\includegraphics[width=1\linewidth]{figures/simple-synthetic-data.png}
%\caption{
  %\lipsum[1]
%}
%\label{fig_synthetic_simple_data}
%\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Real Data Application}

\subsection{Apply the standard method to ICEGRAV}

\subsection{Describe ICEGRAV}

\subsection{Show the original data (TFA points)}

\subsection{Show the location of the deep sources and the block averaged data}

\subsection{Show residuals from deep sources}

\subsection{Show residuals from GB}

\subsection{Grid predictions of TFA and |B|}

\subsection{Brief discussion (or in a separate section)}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\lipsum[1]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Open research}

The Python source code used to produce all results and figures presented here
is available at \url{https://github.com/\GitHubRepository} and
\url{https://doi.org/\ArchiveDOI} under the MIT open-source license.

Here we should cite all of the main software used, like Jupyter, numpy, scipy,
matplotlib, Fatiando, etc.

Cite any data sources as well.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

We are indebted to the developers and maintainers of the open-source software
without which this work would not have been possible.
Acknowledge any non-author contributors to this study.
Statement about funding.

% Thank the editors and reviewers after review.
